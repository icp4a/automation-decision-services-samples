{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.12", "language": "python"}, "language_info": {"name": "python", "version": "3.12.11", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": false, "sideBar": true, "skip_h1_title": false, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {"height": "458px", "left": "10px", "top": "150px", "width": "212px"}, "toc_section_display": true, "toc_window_display": true}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "<table style=\"border: none\" align=\"left\">\n   <tr style=\"border: none\">\n      <th style=\"border: none\"><font face=\"verdana\" size=\"5\" color=\"black\"><b>Build a Loan default PMML scoring model with scikit-learn in Watson ML </b></th>\n      <th style=\"border: none\"><img src=\"https://github.com/pmservice/customer-satisfaction-prediction/blob/master/app/static/images/ml_icon_gray.png?raw=true\" alt=\"Watson Machine Learning icon\" height=\"40\" width=\"40\"></th>\n   </tr>\n</table>", "metadata": {}}, {"cell_type": "markdown", "source": "This notebook contains steps and code to get a loan dataset, create a predictive model, and start scoring new data. This notebook introduces commands for getting data and for basic data cleaning and exploration, model creation, model training, model persistence, model deployment, and scoring.\n\nSome familiarity with Python is helpful. This notebook uses Python 3.\n\n\n## Learning goals\n\nYou will learn how to:\n\n-  Load a CSV file into a Pandas DataFrame.\n-  Explore data.\n-  Prepare data for training and evaluation.\n-  Create a scikit-learn machine learning model.\n-  Train and evaluate a model.\n-  Save the model as PMML file.\n\n\n\n## Contents\n\nThis notebook contains the following parts:\n\n1.\t[Set up](#setup)\n2.\t[Load and explore data](#load)\n3.\t[Create a Scikit learn machine learning model](#model)\n4.\t[Store the model in Watson Machine Learning provider](#provider)\n5.\t[Summary and next steps](#summary)", "metadata": {}}, {"cell_type": "markdown", "source": "<a id=\"setup\"></a>\n## 1. Set up\n\nBefore you use the sample code in this notebook,you create a <a href=\"https://cloud.ibm.com/catalog?category=ai#services\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance (a lite plan is offered and information about how to create the instance is <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-samples-overview.html\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)\n", "metadata": {}}, {"cell_type": "markdown", "source": "<a id=\"load\"></a>\n## 2. Load and explore data", "metadata": {}}, {"cell_type": "markdown", "source": "In this section you will load the data as a Pandas DataFrame and perform a basic exploration.\n\nLoad the data to the Pandas DataFrame by using *wget* to upload the data to gpfs and then use pandas *read* method to read data. ", "metadata": {}}, {"cell_type": "code", "source": "#Install and import the ibm-watsonx-ai and dependecies\n!pip install wget\n!pip install -U ibm-watsonx-ai | tail -n 1", "metadata": {"id": "8488c25f-1455-405c-a57d-299dd01ebc8b"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "import wget\nlink_to_data = 'https://raw.githubusercontent.com/ODMDev/decisions-on-spark/master/data/miniloan/miniloan-payment-default-cases-v2.0.csv'\nfilename = wget.download(link_to_data)\n\nprint(filename)", "metadata": {"id": "3688ee15-a8e4-4240-b4ca-f1338466a7ae"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "Import required libraires to create our Panda DataFrame", "metadata": {}}, {"cell_type": "code", "source": "import numpy as np\nimport pandas as pd", "metadata": {"id": "a438b3d4-702e-4776-8d4e-a7176d4b891c"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "Load the file to Pandas DataFrame using code below", "metadata": {}}, {"cell_type": "code", "source": "used_names = ['creditScore', 'income', 'loanAmount', 'monthDuration', 'rate', 'yearlyReimbursement', 'paymentDefault']\n\ndf = pd.read_csv(\n    filename,\n    header=0,\n    delimiter=r'\\s*,\\s*',\n    engine='python'\n).replace(\n    [np.inf, -np.inf], np.nan\n).dropna().loc[:, used_names]", "metadata": {"id": "7282b8c0-a42e-430b-bd3f-c568ac51191d"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "Explore the loaded data by using the following Pandas DataFrame methods:\n-  print types\n-  print top ten records\n-  count all records", "metadata": {}}, {"cell_type": "code", "source": "# convert all columns of DataFrame to float to avoid scaler warnings\ndf = df.astype({'creditScore': float, \"income\": np.float64, \"loanAmount\": np.float64, \"monthDuration\": np.float64, \"yearlyReimbursement\": np.float64, \"paymentDefault\": np.int64})\ndf.dtypes", "metadata": {"id": "0c963e98-6463-4ca0-9e23-29cfbbd9f62b"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "As you can see, the data contains five fields. default field is the one you would like to predict (label).", "metadata": {}}, {"cell_type": "code", "source": "df.head()", "metadata": {"id": "da04ccf8-7d94-40e1-b5ae-af4a31e76e3f"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "print(\"Number of records: \" + str(len(df)))", "metadata": {"id": "9d6285f9-6fb6-4a1a-af02-72b9c4bda94e"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "<a id=\"model\"></a>\n## 3. Create a Scikit learn machine learning model\n\nIn this section you will learn how to:\n\n- [3.1 Prepare data](#prep)\n- [3.2 Create a model](#pipe)\n- [3.3 Train a model](#train)\n- [3.4 Save as PMML file](#save)\n", "metadata": {}}, {"cell_type": "markdown", "source": "### 3.1 Prepare data<a id=\"prep\"></a>\n\nIn this subsection you will split your data into: \n- train data set\n- test data set\n- predict data set", "metadata": {}}, {"cell_type": "code", "source": "splitted_data = np.array_split(df.sample(frac=1, random_state=42), [int(.8*len(df)), int((.8+.18)*len(df))])\ntrain_data = splitted_data[0]\ntest_data = splitted_data[1]\npredict_data = splitted_data[2]\n\nprint(\"Number of training records: \" + str(len(train_data)))\nprint(\"Number of testing records : \" + str(len(test_data)))\nprint(\"Number of prediction records : \" + str(len(predict_data)))", "metadata": {"id": "270bd3f3-bcd5-4c7f-9c5f-8c2b03884b10"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "As you can see your data has been successfully split into three data sets: \n\n-  The train data set, which is the largest group, is used for training.\n-  The test data set will be used for model evaluation and is used to test the assumptions of the model.\n-  The predict data set will be used for prediction.", "metadata": {}}, {"cell_type": "markdown", "source": "### 3.2 Create a ML model and pipeline<a id=\"pipe\"></a>\n\nIn this section you will create a Scikit-Learn machine learning model and then train the model.\n\nIn the first step you need to import the Scikit-Learn machine learning packages that will be needed in the subsequent steps.", "metadata": {}}, {"cell_type": "code", "source": "from sklearn.linear_model import SGDClassifier\nfrom sklearn.preprocessing import StandardScaler", "metadata": {"id": "375c6896-f0ae-48a5-94cf-624ad02efcc4"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "Now construct the model. A linear model with Stochastic Gradient Descent is used in the following example. We use a pipeline to add an input scaling step.", "metadata": {}}, {"cell_type": "code", "source": "clf = SGDClassifier(loss=\"log_loss\", penalty=\"l2\", random_state=42, tol=1e-3)\nscaler = StandardScaler()", "metadata": {"id": "d1f82d26-c794-46a3-a17a-d2b4496891af"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "You then create a simple pipeline to first scale the input parameter values and then apply the model.", "metadata": {}}, {"cell_type": "code", "source": "from sklearn.pipeline import Pipeline\n\npipeline = Pipeline([\n    ('standardize', scaler),\n    (\"classifier\", clf)\n])", "metadata": {"id": "457a7a3a-2b89-46ab-b783-3020eb47b328"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "### 3.3 Train the model<a id=\"train\"></a>\nNow, you can train your Random Forest model by using the previously defined **pipeline** and **train data**.", "metadata": {}}, {"cell_type": "code", "source": "train_data.dtypes", "metadata": {"id": "7ce70dec-20b7-431d-8062-42804df304e2"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "x_train_data = train_data.loc[:, used_names[:-1]]\ny_train_data = train_data.loc[:, used_names[-1]]", "metadata": {"id": "51c88d17-f6d1-45a5-be95-3878cb39614c"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "pipeline.fit(x_train_data, y_train_data)\n\n# we defined a variable trainedAt to keep track of when the model was trained\nimport datetime;\nts = datetime.datetime.now()\ntrainedAt = ts.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\")", "metadata": {"id": "294458af-40c6-4751-81a7-8f0d93e5d296"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "You can check your **model accuracy** now. Use **test data** to evaluate the model.", "metadata": {}}, {"cell_type": "code", "source": "x_test_data = test_data.loc[:, used_names[:-1]]\ny_test_data = test_data.loc[:, used_names[-1]]\n\npredictions = pipeline.predict(x_test_data)", "metadata": {"id": "7422ecd8-7e3d-4f94-9ed3-2f1155af9ef0"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "We define a **metrics** variable to keep track of the metrics values", "metadata": {}}, {"cell_type": "code", "source": "from sklearn.metrics import mean_squared_error, classification_report, balanced_accuracy_score, accuracy_score, confusion_matrix\n\nmetrics = []\n\nname = \"Coefficient of determination R^2\"\nr2 = pipeline.score(x_test_data, y_test_data)\nmetrics.append({ \"name\": name, \"value\": r2 })\n\nname = \"Root Mean Squared Error (RMSE)\"\nrmse = mean_squared_error(y_test_data, predictions)\nmetrics.append({ \"name\": name, \"value\": rmse })\n\nname = \"Accuracy\"\nacc = accuracy_score(y_test_data, predictions)\nmetrics.append({ \"name\": name, \"value\": acc })\n\nname = \"Balanced accuracy\"\nbalanced_acc = balanced_accuracy_score(y_test_data, predictions)\nmetrics.append({ \"name\": name, \"value\": balanced_acc })\n\nname = \"Confusion Matrix\"\nconfusion_mat = confusion_matrix(y_test_data, predictions, labels=[0, 1])\nmetrics.append({ \"name\": name, \"value\": str(confusion_mat.tolist()) })\n\nfor metric in metrics:\n    print(metric[\"name\"], \"on test data =\", metric[\"value\"])", "metadata": {"id": "fc7aa96b-2f2c-4014-8293-10d02b9f1e11"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "print(classification_report(y_test_data, predictions))", "metadata": {"id": "8ff28909-0924-4946-8ae8-db35074dd45a"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "### 3.4 Save as pmml file <a id=\"save\"></a>", "metadata": {}}, {"cell_type": "code", "source": "!pip install nyoka==4.3.0", "metadata": {"id": "d6512c2c-0c51-4bdc-991d-d95191974626"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "model_name = type(clf).__name__\nscaler_name = type(scaler).__name__\n\nfrom nyoka import skl_to_pmml\nfeatures=x_train_data.columns\ntarget=\"paymentDefault\"\npmml_filename = \"ML-Sample-\" + model_name + '-' + scaler_name + \"-pmml.xml\"\nskl_to_pmml(pipeline, features, target, pmml_filename)\nprint(pmml_filename)", "metadata": {"id": "63ce2edd-86b6-449a-95c7-857f39237180"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "<a id=\"provider\"></a>\n## 4. Store the model in Watson Machine Learning Provider\n", "metadata": {}}, {"cell_type": "markdown", "source": "In this section you will learn how to use Python client libraries to store your pipeline and model in WML repository.\n\n- [4.1 Import the libraries](#lib)\n- [4.2 Save model](#save)\n- [4.3 Invoke model](#local)", "metadata": {}}, {"cell_type": "markdown", "source": "### 4.1 Import the libraries<a id=\"lib\"></a>", "metadata": {}}, {"cell_type": "markdown", "source": "Authenticate to the Watson Machine Learning service on IBM Cloud.\n\n**Tip**: Authentication information (your credentials) can be found in the <a href=\"https://cloud.ibm.com/iam/apikeys\" target=\"_blank\" rel=\"noopener no referrer\">Service credentials</a> tab of the service instance that you created on IBM Cloud. \n\nIf you cannot see the **instance_id** field in **Service Credentials**, click **New credential (+)** to generate new authentication information. \n\n**Action**: Enter your Watson Machine Learning service instance credentials here.", "metadata": {}}, {"cell_type": "code", "source": "from ibm_watsonx_ai import Credentials\n\nwml_credentials = Credentials(\n                   url=\"TO BE SET\",  # example: \"https://eu-gb.ml.cloud.ibm.com\"\n                   api_key=\"TO BE SET\"\n)", "metadata": {"id": "2ed19bf9-ee0d-4dcb-bc7f-dccbc0faa182"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "from ibm_watsonx_ai import APIClient\n\nclient = APIClient(wml_credentials)", "metadata": {"id": "7f7949d3-3152-4a3e-b23a-b5cfa1828b9b"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "### 4.2 Save the pipeline and deploy model<a id=\"save\"></a>", "metadata": {}}, {"cell_type": "markdown", "source": "In this subsection you will learn how to save pipeline and model artifacts to your Watson Machine Learning instance.", "metadata": {}}, {"cell_type": "markdown", "source": "First, you need to create a space that will be used for deploying models. If you do not have space already created, you can use  <a href=\"https://dataplatform.cloud.ibm.com/ml-runtime/spaces?context=cpdaas\" target=\"_blank\" rel=\"noopener no referrer\">Deployment Spaces Dashboard</a> to create one.\n\n- Click New Deployment Space\n- Create an empty space\n- Select Cloud Object Storage\n- Select Watson Machine Learning instance and press Create\n- Copy space_id and paste it below", "metadata": {}}, {"cell_type": "code", "source": "space_id ='TO BE SET'\nclient.set.default_space(space_id)", "metadata": {"id": "7b3e0b7c-4c57-4f64-bf45-491ef832d14e"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "Publish model directly from pipeline.", "metadata": {}}, {"cell_type": "code", "source": "input_data_schema={\n    'id': '1', \n    'type': 'struct', \n    'fields': [\n        {  \n            'name': 'creditScore',\n            'nullable': True,\n            'type': 'float64'\n        },\n        {   \n            'name': 'income',\n            'nullable': True,\n            'type': 'float64'\n        },\n        {   \n            'name': 'loanAmount',\n            'nullable': True,\n            'type': 'float64'\n        },\n        {   \n            'name': 'monthDuration',\n            'nullable': True,\n            'type': 'float64'\n        },\n        {  \n            'name': 'rate',\n            'nullable': True,\n            'type': 'float64'\n        },\n        {   \n            'name': 'yearlyReimbursement',\n            'nullable': True,\n            'type': 'float64'\n        }\n]}", "metadata": {"id": "a06de1aa-b9d9-447d-a670-df9af0cd3108"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "sofware_spec_uid = client.software_specifications.get_id_by_name(\"pmml-3.0_4.3\")\n\nmetadata = {\n            client.repository.ModelMetaNames.NAME: 'Payment Default - PMML',\n            client.repository.ModelMetaNames.TYPE: 'pmml_4.3',\n            client.repository.ModelMetaNames.INPUT_DATA_SCHEMA: input_data_schema,\n            client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: sofware_spec_uid,\n            client.repository.ModelMetaNames.LABEL_FIELD: 'paymentDefault',\n\n}\n\npublished_model_details = client.repository.store_model(model=pmml_filename, meta_props=metadata)", "metadata": {"id": "e09fc73d-65c6-433e-815d-85414a8b3d96"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "model_uid = client.repository.get_model_id( published_model_details )\n\nprint( \"model_uid: \", model_uid )", "metadata": {"id": "c0966ff6-c96e-441f-b1b5-98c9a06878a5"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "deployment_name  = \"Payment Default deployment\"\ndeployment_desc  = \"Online deployment of Loan payment default predictive service in pmml\"\ndeployment_metadata = {\n                        client.deployments.ConfigurationMetaNames.NAME: deployment_name, \n                        client.deployments.ConfigurationMetaNames.DESCRIPTION: deployment_desc,\n                        client.deployments.ConfigurationMetaNames.ONLINE: {}\n}\ndeployment       = client.deployments.create(artifact_uid=model_uid, meta_props=deployment_metadata)\nscoring_endpoint = client.deployments.get_scoring_href( deployment )\nprint( \"scoring_endpoint: \", scoring_endpoint )", "metadata": {"id": "4d64fa13-d40a-4228-af74-a48b164bf6f6"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "**Tip**: Use `client.repository.ModelMetaNames.show()` to get the list of available props.", "metadata": {}}, {"cell_type": "code", "source": "client.repository.ModelMetaNames.show()", "metadata": {"id": "90986138-380d-4760-a472-f2c898485e01"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "<a id=\"local\"></a>\n### 4.3 Invoke model\n", "metadata": {}}, {"cell_type": "markdown", "source": "In this subsection you will score the *predict_data* data set.\nYou will learn how to invoke a saved model from a specified instance of Watson Machine Learning.", "metadata": {}}, {"cell_type": "code", "source": "deployment_id = client.deployments.get_id(deployment)\n\nx_predict_data = predict_data.loc[:, used_names[:-1]]\ny_predict_data = predict_data.loc[:, used_names[-1]]\n\n#scoring_payload = {\n#    \"fields\": x_predict_data.columns.values.tolist(),\n#    \"values\": x_predict_data.values.tolist()\n#}\n\nscoring_payload = {\n    client.deployments.ScoringMetaNames.INPUT_DATA: [\n        {\n            'fields': x_predict_data.columns.values.tolist(),\n            'values': x_predict_data.values.tolist()\n        }]\n}\npredictions_predict_data = client.deployments.score(deployment_id, scoring_payload)\n\n#print(json.dumps(predictions_predict_data, indent=4))\npredictions_predict_data", "metadata": {"id": "8ff76629-9f12-44e5-ae1b-7acf3665b719"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "Preview some results metrics", "metadata": {}}, {"cell_type": "code", "source": "label_predictions = []\nfor result in predictions_predict_data['predictions'][0].get('values'):\n    if result[0] >= 0.5:\n        label_predictions.append(0)\n    elif result[0] < 0.5:\n        label_predictions.append(1)\n        \nbalanced_acc = balanced_accuracy_score(y_predict_data, label_predictions)\n\nconfusion_mat = confusion_matrix(y_predict_data, label_predictions, labels=[0, 1])\n\nacc = accuracy_score(y_predict_data, label_predictions)\n\nprint('Accuracy', acc)\nprint('Balanced accuracy', balanced_acc)\nprint('Confusion Matrix', confusion_mat)", "metadata": {"id": "8a901c43-8e84-448c-bf43-0bf63d09e694"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "<a id=\"summary\"></a>\n## 5. Summary and next steps\nYou successfully completed this notebook!   \nCheck out the [Online Documentation](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-samples-overview.html) for more samples, tutorials, documentation, how-tos, and blog posts. ", "metadata": {}}, {"cell_type": "markdown", "source": "### Authors\n\nThis notebook was inspired by original notebook written by Pierre Feillet using Apache Spark and Watson Machine Learning.", "metadata": {}}]}